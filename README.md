ðŸ§  Cymbiotika AI Chatbot
This is a full-stack AI chatbot built for Cymbiotika, capable of answering product-specific questions using local embeddings, routing support queries, and handling general wellness chat. It uses FastAPI, LangGraph, Chroma, HuggingFace embeddings, and Llama 3 via Ollama, with a lightweight React front-end.

ðŸ’» Run Locally
Hereâ€™s how to get everything running on your machine.

1. Clone the repo
bash
Copy
Edit
git clone https://github.com/your-username/cymbiotika-ai-chatbot.git
cd cymbiotika-ai-chatbot
2. Set up Python backend
bash
Copy
Edit
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
3. Set up Node frontend
bash
Copy
Edit
cd frontend
npm install
4. Install and run Ollama
Download and install Ollama if you havenâ€™t already, then:

bash
Copy
Edit
ollama run llama3
This will download and launch the model. Keep it running in a separate terminal.

5. Start the backend
bash
Copy
Edit
uvicorn chat:app --reload --host 0.0.0.0 --port 8000
6. Start the frontend
bash
Copy
Edit
cd frontend
npm run dev
Visit: http://localhost:5173

ðŸ§© How It Works
Backend: FastAPI handles routing with LangGraph to decide between product lookup, support, or general chat.

Vector DB: Product data is embedded with MiniLM and stored in Chroma (./chroma_db).

LLM: All answers are generated by Llama 3 (via Ollama).

Frontend: React + Vite powers the chat interface with mode/category selection.

